{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e05da7-4d52-4d88-911b-9e382a2e5524",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 📘 Sentence Similarity: Symbolic vs Semantic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f21715-dd68-4713-b2b7-aae25002ad03",
   "metadata": {},
   "source": [
    "In this notebook, we explore two different approaches to measuring how similar two pieces of text are.  \n",
    "This is useful in many real-world tasks, such as:\n",
    "\n",
    "- Evaluating machine translations\n",
    "- Detecting duplicate sentences\n",
    "- Comparing user input with reference answers\n",
    "- Measuring content overlap across models\n",
    "\n",
    "## 🎯 Goal\n",
    "\n",
    "We compare two fundamentally different techniques:\n",
    "\n",
    "1. **SequenceMatcher** — a traditional symbolic algorithm that compares how similar two strings are based on characters or words.\n",
    "2. **SentenceTransformer** — a modern semantic method that uses neural networks to compare meaning, not just text form.\n",
    "\n",
    "Each approach is explained with short code examples and use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39448051-13f8-4de6-9e6f-7b51e8aa2825",
   "metadata": {},
   "source": [
    "## 🔁 Both Methods Compare Strings – But in Completely Different Ways\n",
    "\n",
    "| 🔍 Characteristic          | `SequenceMatcher`                       | `SentenceTransformer`                             |\n",
    "|---------------------------|-----------------------------------------|---------------------------------------------------|\n",
    "| **What it compares**      | Characters or words                     | Sentence meaning (semantics)                      |\n",
    "| **Understands meaning?**  | ❌ No                                    | ✅ Yes                                             |\n",
    "| **Based on**              | Common substrings (technically)         | Vector representation from a trained neural net   |\n",
    "| **Output**                | Match percentage by characters          | Cosine similarity between sentence vectors        |\n",
    "| **Used when**             | Exact form matters (typos, logins)      | Meaning matters, even if wording is different     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef5706-c9fa-43a0-a95c-7c2c9091182f",
   "metadata": {},
   "source": [
    "## 🔣 SequenceMatcher – Symbolic Similarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029c6654-1e6e-4f7a-ac1c-f550c1599baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceMatcher similarity: 73%\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "a = \"I like cats\"\n",
    "b = \"I like dogs\"\n",
    "\n",
    "similarity = SequenceMatcher(None, a, b).ratio()\n",
    "print(f\"SequenceMatcher similarity: {round(similarity * 100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4914b-5d09-4fba-9dc9-105fa28916b8",
   "metadata": {},
   "source": [
    "- 🔍 It checks for **matching subsequences** (e.g., `\"I like cats\"` vs `\"I like dogs\"`).\n",
    "- ❌ It **does not understand meaning** — only surface-level similarity.\n",
    "- ✅ Useful for catching **typos, near-duplicates, or string similarity**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbae05-bc48-4cd0-a0b8-65630e8235fa",
   "metadata": {},
   "source": [
    "## 🔢 SentenceTransformer – Semantic Similarity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68982719-ea5f-46c4-acb4-afd1e119ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vadim/jupyter/semantic_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic similarity: 78%\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "a = \"I like cats\"\n",
    "b = \"I adore kittens\"\n",
    "\n",
    "emb1 = model.encode([a])[0]\n",
    "emb2 = model.encode([b])[0]\n",
    "\n",
    "cos_sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "print(f\"Semantic similarity: {round(cos_sim * 100)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a12ff9-7e07-4aaf-9623-f13a85c366bc",
   "metadata": {},
   "source": [
    "- 🧠 It encodes sentences into **dense vectors** that represent meaning.\n",
    "- ✅ It can detect **semantic similarity**, even if the words are different.\n",
    "- 📏 Uses **cosine similarity** to compare how close two sentences are in meaning.\n",
    "- 🔎 Great for comparing **translations, paraphrases, or responses** where wording may vary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53da092-f615-4a31-a758-3106b1d29c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Current working directory: /Users/vadim/VST-VoiceOver/notebooks\n",
      "✅ File found: whisper_models/tiny-de-2min.srt\n",
      "✅ File found: whisper_models/base-de-2min.srt\n",
      "✅ File found: whisper_models/smal-de-2min.srt\n",
      "✅ File found: whisper_models/medium-de-2min.srt\n",
      "✅ File found: whisper_models/large_v1-de-2min.srt\n",
      "✅ File found: whisper_models/large_v2-de-2min.srt\n",
      "✅ File found: whisper_models/large_v3-de-2min.srt\n",
      "✅ File found: whisper_models/large-turbo-v3-de-2min.srt\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Model Comparison | original | tiny | base | small | medium | large_v1 | large_v2 | large_v3 | large-turbo-v3 |\n",
       "|----|----|----|----|----|----|----|----|----|----|\n",
       "| **original** | – | 52% | 90% | 24% | 24% | 97% | 97% | 97% | 96% |\n",
       "| **tiny** | 60% | – | 44% | 49% | 38% | 47% | 51% | 35% | 46% |\n",
       "| **base** | 90% | 50% | – | 90% | 89% | 89% | 89% | 91% | 92% |\n",
       "| **small** | 97% | 55% | 90% | – | 95% | 98% | 96% | 84% | 92% |\n",
       "| **medium** | 91% | 46% | 76% | 76% | – | 94% | 91% | 77% | 89% |\n",
       "| **large_v1** | 97% | 54% | 89% | 98% | 92% | – | 96% | 96% | 94% |\n",
       "| **large_v2** | 97% | 53% | 90% | 24% | 24% | 96% | – | 98% | 97% |\n",
       "| **large_v3** | 97% | 44% | 78% | 24% | 24% | 87% | 98% | – | 94% |\n",
       "| **large-turbo-v3** | 96% | 54% | 91% | 71% | 91% | 94% | 97% | 97% | – |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown table saved to: outputs/vergleich.md\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"📂 Current working directory:\", os.getcwd())\n",
    "\n",
    "# Define the reference/original text\n",
    "original_text = \"\"\"\n",
    "Herzlich willkommen zu diesem Tutorial in der Reihe Texture Mapping. Dieses dritte Tutorial soll Ihnen zeigen, wie Sie eine Textur eines Baumstammes, den Sie hier sehen, auf einen einfachen Zylinder mappen können. Wir haben hier zwei Texturen verwendet, eine Textur für den Stamm und eine weitere Textur hier vom Schnitt des Baumstammes und ich zeige Ihnen in ein paar wenigen Schritten, wie einfach das möglich ist, hier die Textur an die richtige Stelle mit Hilfe vom UV-Mapping zu bekommen.\n",
    "Dann starten wir mit dem Blender Default Screen, hier der Würfel. Ich lösche den Würfel und gebe einen Zylinder dazu, den ich etwas in Z skaliere. Wir sehen hier, dass wir hier jetzt nicht näher auf die Modellierung des Baumstumpfes eingehen, sondern nur auf, wie wir optimal die Textur auf diesen Zylinder mappen können.\n",
    "Gut, wir schauen uns nun die UV-Editing-Tools an. Wir sehen hier auch in einem der früheren Tutorials, ist der Zylinder bereits richtig gemappt. An dieser Stelle hier, wir sehen hier die Seite des Zylinders und die Ober- und die Unterseite des Zylinders.\n",
    "Das ist bei Default-Objekten so der Fall.\n",
    "\"\"\"\n",
    "\n",
    "# Define file paths for subtitle files\n",
    "file_paths = {\n",
    "    \"tiny\": \"whisper_models/tiny-de-2min.srt\",\n",
    "    \"base\": \"whisper_models/base-de-2min.srt\",\n",
    "    \"small\": \"whisper_models/smal-de-2min.srt\",\n",
    "    \"medium\": \"whisper_models/medium-de-2min.srt\",\n",
    "    \"large_v1\": \"whisper_models/large_v1-de-2min.srt\",\n",
    "    \"large_v2\": \"whisper_models/large_v2-de-2min.srt\",\n",
    "    \"large_v3\": \"whisper_models/large_v3-de-2min.srt\",\n",
    "    \"large-turbo-v3\": \"whisper_models/large-turbo-v3-de-2min.srt\"\n",
    "}\n",
    "\n",
    "# Verify that all files exist\n",
    "for name, path in file_paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"❌ File not found: {path}\")\n",
    "    else:\n",
    "        print(f\"✅ File found: {path}\")\n",
    "\n",
    "# Function to read SRT files and extract plain text\n",
    "def read_srt_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    text = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.isdigit() and \"-->\" not in line:\n",
    "            text.append(line)\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Read subtitle texts\n",
    "texts = {name: read_srt_text(path) for name, path in file_paths.items()}\n",
    "texts[\"original\"] = original_text\n",
    "\n",
    "# Build similarity matrix\n",
    "model_names = [\"original\"] + [name for name in texts.keys() if name != \"original\"]\n",
    "\n",
    "similarity_matrix = pd.DataFrame(index=model_names, columns=model_names)\n",
    "\n",
    "for name1 in model_names:\n",
    "    for name2 in model_names:\n",
    "        if name1 == name2:\n",
    "            similarity_matrix.loc[name1, name2] = \"–\"\n",
    "        else:\n",
    "            ratio = SequenceMatcher(None, texts[name1], texts[name2]).ratio()\n",
    "            similarity_matrix.loc[name1, name2] = f\"{round(ratio * 100)}%\"\n",
    "\n",
    "# Generate Markdown table\n",
    "md_table = \"| Model Comparison | \" + \" | \".join(model_names) + \" |\\n\"\n",
    "md_table += \"|\" + \"----|\" * (len(model_names) + 1) + \"\\n\"\n",
    "\n",
    "for name1 in model_names:\n",
    "    row = f\"| **{name1}** \"\n",
    "    for name2 in model_names:\n",
    "        row += f\"| {similarity_matrix.loc[name1, name2]} \"\n",
    "    row += \"|\\n\"\n",
    "    md_table += row\n",
    "\n",
    "# Display the table in the notebook\n",
    "display(Markdown(md_table))\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the Markdown table\n",
    "output_path = os.path.join(output_dir, \"vergleich.md\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_table)\n",
    "\n",
    "print(f\"✅ Markdown table saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95a723-a09c-409c-b9e1-11c5ea0c06ed",
   "metadata": {},
   "source": [
    "## ✅ Summary of the SequenceMatcher Evaluation\n",
    "\n",
    "In this part of the notebook, I used Python’s `SequenceMatcher` to compare the reference transcript with the outputs from various Whisper models.\n",
    "\n",
    "- This algorithm works by comparing **character sequences**, not the meaning of sentences.\n",
    "- It gives a similarity score (in %) based on how much the outputs structurally match the original.\n",
    "- It's a fast and simple method that's useful for spotting surface-level changes — like typos or word order shifts.\n",
    "\n",
    "### 🔍 What I observed from the results:\n",
    "- Some models (like `small`, `large_v1`, `large_v2`) showed very high structural similarity to the original — up to 97–98%.\n",
    "- Others (like `tiny` and `medium`) had much lower scores in comparison, which may point to rephrasing, skipped words, or alignment issues.\n",
    "- Still, this method doesn’t tell us if two outputs have **similar meaning** — just that they **look similar on the surface**.\n",
    "\n",
    "> 🧠 So for deeper analysis (e.g., semantic similarity), I'll need a different approach — like using `SentenceTransformer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830e0a3e-d007-4ed2-9aea-2a3664b5804e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found: translate_models/Google_V1.srt\n",
      "✅ Found: translate_models/DeepL_V2.srt\n",
      "✅ Found: translate_models/ChatGPT-mini-3o.srt\n",
      "✅ Found: translate_models/GPT-4o-mini.srt\n",
      "✅ Found: translate_models/GPT-4o.srt\n",
      "✅ Found: translate_models/GPT-4o-turbo.srt\n",
      "✅ Found: translate_models/GPT-3.5-turbo.srt\n",
      "✅ Found: translate_models/GPT-4.srt\n",
      "✅ Found: translate_models/MyMemory.srt\n",
      "✅ Found: translate_models/groq.srt\n",
      "✅ Found: translate_models/winstxnhdw-HLLB.srt\n",
      "✅ Found: translate_models/Ollama.srt\n",
      "✅ Found: translate_models/DeepSeek-R1.srt\n",
      "✅ Found: translate_models/gemma3.srt\n",
      "✅ Found: translate_models/zongweigemma3-translator1b.srt\n",
      "✅ Found: translate_models/gimini-2.0-flash.srt\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Model Comparison | Google_V1 | DeepL_V2 | ChatGPT-mini-3o | GPT-4o-mini | GPT-4o | GPT-4o-turbo | GPT-3.5-turbo | GPT-4 | MyMemory | groq | winstxnhdw-HLLB | Ollama | DeepSeek-R1 | gemma3 | zongweigemma3-translator1b | gimini-2.0-flash |\n",
       "|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|\n",
       "| **Google_V1** | – | 38% | 25% | 25% | 25% | 25% | 24% | 24% | 30% | 29% | 36% | 29% | 39% | 27% | 27% | 32% |\n",
       "| **DeepL_V2** | 38% | – | 33% | 33% | 32% | 32% | 32% | 31% | 41% | 52% | 54% | 52% | 59% | 38% | 49% | 55% |\n",
       "| **ChatGPT-mini-3o** | 25% | 33% | – | 98% | 96% | 97% | 97% | 96% | 45% | 42% | 38% | 39% | 33% | 46% | 38% | 38% |\n",
       "| **GPT-4o-mini** | 25% | 33% | 98% | – | 96% | 97% | 98% | 96% | 45% | 43% | 39% | 40% | 33% | 47% | 39% | 39% |\n",
       "| **GPT-4o** | 25% | 32% | 96% | 96% | – | 96% | 96% | 97% | 43% | 41% | 38% | 39% | 32% | 45% | 38% | 38% |\n",
       "| **GPT-4o-turbo** | 25% | 32% | 97% | 97% | 96% | – | 97% | 98% | 44% | 42% | 38% | 40% | 31% | 47% | 39% | 39% |\n",
       "| **GPT-3.5-turbo** | 24% | 32% | 97% | 98% | 96% | 97% | – | 96% | 44% | 43% | 38% | 39% | 32% | 46% | 38% | 38% |\n",
       "| **GPT-4** | 24% | 31% | 96% | 96% | 97% | 98% | 96% | – | 44% | 41% | 37% | 39% | 32% | 46% | 39% | 39% |\n",
       "| **MyMemory** | 30% | 41% | 45% | 45% | 43% | 44% | 44% | 44% | – | 61% | 37% | 47% | 40% | 88% | 48% | 58% |\n",
       "| **groq** | 29% | 52% | 42% | 43% | 41% | 42% | 43% | 41% | 61% | – | 40% | 63% | 51% | 59% | 61% | 72% |\n",
       "| **winstxnhdw-HLLB** | 36% | 54% | 38% | 39% | 38% | 38% | 38% | 37% | 37% | 40% | – | 42% | 64% | 36% | 41% | 41% |\n",
       "| **Ollama** | 29% | 52% | 39% | 40% | 39% | 40% | 39% | 39% | 47% | 63% | 42% | – | 57% | 47% | 84% | 46% |\n",
       "| **DeepSeek-R1** | 39% | 59% | 33% | 33% | 32% | 31% | 32% | 32% | 40% | 51% | 64% | 57% | – | 38% | 56% | 50% |\n",
       "| **gemma3** | 27% | 38% | 46% | 47% | 45% | 47% | 46% | 46% | 88% | 59% | 36% | 47% | 38% | – | 47% | 57% |\n",
       "| **zongweigemma3-translator1b** | 27% | 49% | 38% | 39% | 38% | 39% | 38% | 39% | 48% | 61% | 41% | 84% | 56% | 47% | – | 49% |\n",
       "| **gimini-2.0-flash** | 32% | 55% | 38% | 39% | 38% | 39% | 38% | 39% | 58% | 72% | 41% | 46% | 50% | 57% | 49% | – |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved more accurate sentence-by-sentence comparison at: outputs/vergleich_sentence_by_sentence.md\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "model_names = [\n",
    "    \"Google_V1\", \"DeepL_V2\", \"ChatGPT-mini-3o\", \"GPT-4o-mini\", \"GPT-4o\", \"GPT-4o-turbo\", \n",
    "    \"GPT-3.5-turbo\", \"GPT-4\", \"MyMemory\", \"groq\", \"winstxnhdw-HLLB\", \n",
    "    \"Ollama\", \"DeepSeek-R1\", \"gemma3\", \"zongweigemma3-translator1b\", \"gimini-2.0-flash\"\n",
    "]\n",
    "\n",
    "file_dir = \"translate_models\"\n",
    "file_paths = {name: os.path.join(file_dir, f\"{name}.srt\") for name in model_names}\n",
    "for name, path in file_paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"❌ File not found: {path}\")\n",
    "    print(f\"✅ Found: {path}\")\n",
    "\n",
    "def read_srt_text(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    text = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.isdigit() and \"-->\" not in line:\n",
    "            text.append(line)\n",
    "    full_text = \" \".join(text)\n",
    "    full_text = full_text.lower()\n",
    "    full_text = re.sub(r\"[^\\w\\s\\.\\?!]\", \"\", full_text)\n",
    "    full_text = re.sub(r\"\\s+\", \" \", full_text).strip()\n",
    "    return re.split(r'(?<=[\\.\\!\\?])\\s+', full_text)\n",
    "\n",
    "# Model with better semantic resolution\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def compare_sentences(sent_list1, sent_list2):\n",
    "    n = min(len(sent_list1), len(sent_list2))\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    emb1 = model.encode(sent_list1[:n])\n",
    "    emb2 = model.encode(sent_list2[:n])\n",
    "    sims = [cosine_similarity([a], [b])[0][0] for a, b in zip(emb1, emb2)]\n",
    "    return round(np.mean(sims) * 100)\n",
    "\n",
    "# Read and encode\n",
    "texts = {name: read_srt_text(path) for name, path in file_paths.items()}\n",
    "\n",
    "# Build similarity matrix\n",
    "similarity_matrix = pd.DataFrame(index=model_names, columns=model_names)\n",
    "for name1 in model_names:\n",
    "    for name2 in model_names:\n",
    "        if name1 == name2:\n",
    "            similarity_matrix.loc[name1, name2] = \"–\"\n",
    "        else:\n",
    "            sim = compare_sentences(texts[name1], texts[name2])\n",
    "            similarity_matrix.loc[name1, name2] = f\"{sim}%\"\n",
    "\n",
    "# Markdown table\n",
    "md_table = \"| Model Comparison | \" + \" | \".join(model_names) + \" |\\n\"\n",
    "md_table += \"|\" + \"----|\" * (len(model_names) + 1) + \"\\n\"\n",
    "for name1 in model_names:\n",
    "    row = f\"| **{name1}** \"\n",
    "    for name2 in model_names:\n",
    "        row += f\"| {similarity_matrix.loc[name1, name2]} \"\n",
    "    row += \"|\\n\"\n",
    "    md_table += row\n",
    "\n",
    "display(Markdown(md_table))\n",
    "\n",
    "# Save table\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"vergleich_sentence_by_sentence.md\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_table)\n",
    "\n",
    "print(f\"✅ Saved more accurate sentence-by-sentence comparison at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad40a3-0c7d-4e63-bb98-9ed2e8f81f1b",
   "metadata": {},
   "source": [
    "## ✅ Summary of the SentenceTransformer Evaluation\n",
    "\n",
    "In this part of the notebook, I used a `SentenceTransformer` model (`all-mpnet-base-v2`) to compare the outputs of various translation systems **sentence by sentence**.\n",
    "\n",
    "- This method captures **semantic similarity**, not just structural or surface overlap.\n",
    "- Each sentence is encoded into a vector, and I compute the **cosine similarity** between sentence pairs.\n",
    "- The final score is the average semantic similarity across all aligned sentences.\n",
    "\n",
    "### 🔍 What the results show:\n",
    "- Models like `GPT-4o`, `GPT-4o-turbo`, and `DeepL` often score high when compared to each other — meaning they produce translations with similar meaning.\n",
    "- Models like `winstxnhdw` or `DeepSeek` tend to diverge more from the rest, possibly due to stylistic or structural differences.\n",
    "- Unlike `SequenceMatcher`, this method is more **robust to rephrasing and different word choices** as long as the meaning stays intact.\n",
    "\n",
    "> 🧠 SentenceTransformer is a better fit when comparing translations based on meaning, not form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28471ea2-39a1-4f59-af6a-270449fa0922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semantic)",
   "language": "python",
   "name": "semantic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
